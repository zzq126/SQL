{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Management Project 01\n",
    "\n",
    "\n",
    "Ziqing Zhu G20525987\n",
    "\n",
    "###  Problem 1 - Word counts (40 points)\n",
    "Part A. Characters in Little Women\n",
    "How many times are each of the following characters mentioned by name in the text of Little Women?\n",
    "\n",
    "• Jo, Beth, Meg, Amy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-16 11:09:04--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/women.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.32.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1053440 (1.0M) [text/plain]\n",
      "Saving to: ‘women.txt.1’\n",
      "\n",
      "women.txt.1         100%[===================>]   1.00M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2016-09-16 11:09:04 (9.31 MB/s) - ‘women.txt.1’ saved [1053440/1053440]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/women.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use grep to select words by their names in the file and then use \"wc -l\" to count lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1355\n",
      "459\n",
      "683\n",
      "645\n"
     ]
    }
   ],
   "source": [
    "!cat women.txt | grep -oE '\\w{{2,}}' | grep -w Jo | wc -l\n",
    "!cat  women.txt | grep -oE '\\w{{2,}}' | grep -w Beth | wc -l\n",
    "!cat women.txt | grep -oE '\\w{{2,}}' | grep -w Meg | wc -l\n",
    "!cat women.txt | grep -oE '\\w{{2,}}' | grep -w Amy| wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B. Juliet and Romeo in Romeo and Juliet\n",
    "How many times do each of the characters Juliet and Romeo have speaking lines in Romeo and Juliet? Keep\n",
    "in mind that this is the text of a play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-16 13:03:17--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/romeo.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.32.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 178983 (175K) [text/plain]\n",
      "Saving to: ‘romeo.txt.1’\n",
      "\n",
      "romeo.txt.1         100%[===================>] 174.79K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2016-09-16 13:03:17 (3.56 MB/s) - ‘romeo.txt.1’ saved [178983/178983]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/romeo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\r\n"
     ]
    }
   ],
   "source": [
    "!grep -w \"Rom.\" romeo.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\r\n"
     ]
    }
   ],
   "source": [
    "!grep -w \"Jul\" romeo.txt | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Problem 2 - Capital Bikeshare (40 points)\n",
    "Part A (20 points)\n",
    "\n",
    "Which 10 Capital Bikeshare stations were the most popular departing stations in Q1 2016? Which 10 were\n",
    "the most popular destination stations in Q1 2016?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-18 11:53:48--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/2016q1.csv.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.32.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10643003 (10M) [application/octet-stream]\n",
      "Saving to: ‘2016q1.csv.zip’\n",
      "\n",
      "2016q1.csv.zip      100%[===================>]  10.15M  18.8MB/s    in 0.5s    \n",
      "\n",
      "2016-09-18 11:53:49 (18.8 MB/s) - ‘2016q1.csv.zip’ saved [10643003/10643003]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/2016q1.csv.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip 2016q1.csv.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mv 2016q1.csv q1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1: Duration (ms)\r\n",
      "  2: Start date\r\n",
      "  3: End date\r\n",
      "  4: Start station number\r\n",
      "  5: Start station\r\n",
      "  6: End station number\r\n",
      "  7: End station\r\n",
      "  8: Bike number\r\n",
      "  9: Member Type\r\n"
     ]
    }
   ],
   "source": [
    "!csvcut -n q1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!csvcut -c5 q1.csv | csvsort | uniq -c > starting-station.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   5514 17th & Corcoran St NW\r\n",
      "   5649 Eastern Market Metro / Pennsylvania Ave & 7th St SE\r\n",
      "   6491 New Hampshire Ave & T St NW\r\n",
      "   6568 14th & V St NW\r\n",
      "   7401 15th & P St NW\r\n",
      "   7479 Thomas Circle\r\n",
      "   8138 Jefferson Dr & 14th St SW\r\n",
      "   9388 Lincoln Memorial\r\n",
      "   9560 Massachusetts Ave & Dupont Circle NW\r\n",
      "  13120 Columbus Circle / Union Station\r\n"
     ]
    }
   ],
   "source": [
    "!cat starting-station.txt | sort -n | tail -10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B (20 points)\n",
    "For the most popular departure station, which 10 bikes were used most in trips departing from there? Which\n",
    "10 bikes were used most in trips ending at the most popular destination station?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!csvcut -c5,8 q1.csv | csvgrep -c1 -m 'Columbus Circle / Union Station' | csvsort -c 2 | uniq -c > departure-bike.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15 Columbus Circle / Union Station,W21076\r\n",
      "     15 Columbus Circle / Union Station,W21450\r\n",
      "     15 Columbus Circle / Union Station,W22080\r\n",
      "     16 Columbus Circle / Union Station,W00714\r\n",
      "     16 Columbus Circle / Union Station,W20540\r\n",
      "     16 Columbus Circle / Union Station,W21239\r\n",
      "     16 Columbus Circle / Union Station,W21538\r\n",
      "     16 Columbus Circle / Union Station,W21641\r\n",
      "     16 Columbus Circle / Union Station,W21867\r\n",
      "     17 Columbus Circle / Union Station,W22227\r\n"
     ]
    }
   ],
   "source": [
    "cat departure-bike.txt | sort -n | tail -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|------------------------------------------------|\r\n",
      "|    13880 Columbus Circle / Union Station       |\r\n",
      "|------------------------------------------------|\r\n",
      "|    11183 Massachusetts Ave & Dupont Circle NW  |\r\n",
      "|     9419 Lincoln Memorial                      |\r\n",
      "|     8975 Jefferson Dr & 14th St SW             |\r\n",
      "|     8092 15th & P St NW                        |\r\n",
      "|     7267 14th & V St NW                        |\r\n",
      "|     6997 Thomas Circle                         |\r\n",
      "|     6245 New Hampshire Ave & T St NW           |\r\n",
      "|     5761 5th & K St NW                         |\r\n",
      "|     5651 17th & Corcoran St NW                 |\r\n",
      "|------------------------------------------------|\r\n"
     ]
    }
   ],
   "source": [
    "!csvcut -c7 q1.csv | csvsort | uniq -c | sort -rn | head -10 | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   5651 17th & Corcoran St NW\r\n",
      "   5761 5th & K St NW\r\n",
      "   6245 New Hampshire Ave & T St NW\r\n",
      "   6997 Thomas Circle\r\n",
      "   7267 14th & V St NW\r\n",
      "   8092 15th & P St NW\r\n",
      "   8975 Jefferson Dr & 14th St SW\r\n",
      "   9419 Lincoln Memorial\r\n",
      "  11183 Massachusetts Ave & Dupont Circle NW\r\n",
      "  13880 Columbus Circle / Union Station\r\n"
     ]
    }
   ],
   "source": [
    "!cat ending-station.txt | sort -n | tail -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!csvcut -c7,8 q1.csv | csvgrep -c1 -m 'Columbus Circle / Union Station' | csvsort -c2 | uniq -c > ending-bike.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15 Columbus Circle / Union Station,W21867\r\n",
      "     15 Columbus Circle / Union Station,W21997\r\n",
      "     16 Columbus Circle / Union Station,W00714\r\n",
      "     16 Columbus Circle / Union Station,W20425\r\n",
      "     16 Columbus Circle / Union Station,W21076\r\n",
      "     16 Columbus Circle / Union Station,W21239\r\n",
      "     16 Columbus Circle / Union Station,W22080\r\n",
      "     16 Columbus Circle / Union Station,W22099\r\n",
      "     17 Columbus Circle / Union Station,W22227\r\n",
      "     18 Columbus Circle / Union Station,W00485\r\n"
     ]
    }
   ],
   "source": [
    "!cat ending-bike.txt | sort -n | tail -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 - Filters (20 points)\n",
    "In class lectures, previous exercises, and Problems 1 and 2 above, you use Unix commands like grep and\n",
    "tr as filters, changing the text lines streaming through the pipeline. In this problem, write small Python\n",
    "programs that act as filters in the same way, where each program serves one filtering purpose. Name each\n",
    "new filter program clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part A (10 points)\n",
    "\n",
    "Demonstrate a pipeline that performs a count of the top ten unique words in Little Women. This may be\n",
    "exactly the same pipeline we have used before.\n",
    "Write a Python filter than replaces grep -oE '\\w{2,}' to split lines of text into one word per line, and\n",
    "write an additional Python filter to replace tr '[:upper:]' '[:lower:]' to transform text into lower case.\n",
    "With your two new filters, repeat the original pipeline, and substitute your new filters as appropriate. You\n",
    "should obtain the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x split2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2233 for\r\n",
      "   2343 she\r\n",
      "   2447 you\r\n",
      "   2503 in\r\n",
      "   2774 it\r\n",
      "   3245 her\r\n",
      "   3523 of\r\n",
      "   5152 to\r\n",
      "   7689 the\r\n",
      "   8155 and\r\n"
     ]
    }
   ],
   "source": [
    "!cat women.txt | grep -oE '\\w{{2,}}' |tr '[:upper:]' '[:lower:]'| sort | uniq -c | sort -n | tail -10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I imported the re package to split words into seperate lines in filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2233 for\r\n",
      "   2343 she\r\n",
      "   2447 you\r\n",
      "   2503 in\r\n",
      "   2774 it\r\n",
      "   3245 her\r\n",
      "   3523 of\r\n",
      "   5152 to\r\n",
      "   7689 the\r\n",
      "   8155 and\r\n"
     ]
    }
   ],
   "source": [
    "!cat women.txt| ./split2.py | ./lower.py | tr -s '\\n' | sort | uniq -c | sort -n | tail -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B (10 points)\n",
    "Write a Python filter that removes at least ten common words of English text, commonly known as “stop\n",
    "words”. Sources of English stop word lists are readily available online, or you may generate your own list\n",
    "from the text.\n",
    "Add your stop word filter to a word count pipeline and show the top 25 words in Little Women with stop\n",
    "words removed. You may re-use your filters from Part A if you wish, although this is not required for full\n",
    "credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x remove-stop-words.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    916 if\r\n",
      "    942 not\r\n",
      "    976 on\r\n",
      "   1014 be\r\n",
      "   1063 had\r\n",
      "   1067 at\r\n",
      "   1118 his\r\n",
      "   1135 so\r\n",
      "   1362 jo\r\n",
      "   1469 but\r\n",
      "   1598 he\r\n",
      "   1854 with\r\n",
      "   1937 that\r\n",
      "   1978 as\r\n",
      "   2033 was\r\n",
      "   2233 for\r\n",
      "   2343 she\r\n",
      "   2447 you\r\n",
      "   2503 in\r\n",
      "   2774 it\r\n",
      "   3245 her\r\n",
      "   3523 of\r\n",
      "   5152 to\r\n",
      "   7689 the\r\n",
      "   8155 and\r\n"
     ]
    }
   ],
   "source": [
    "!cat women.txt| ./remove-stop-words.py |./split2.py | ./lower.py |  grep -v '^$'| sort | uniq -c | sort -n | tail -25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Extra credit (10 points)\n",
    "Use GNU parallel to count the 25 most common words across all the 109 texts in the zip file provided, with\n",
    "stop words removed. You may re-use your filters from Problem 3.\n",
    "Use the texts available at https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-\n",
    "schedule/master/projects/project-01/texts.zip for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-18 17:12:55--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/texts.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.32.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12668137 (12M) [application/octet-stream]\n",
      "Saving to: ‘texts.zip.1’\n",
      "\n",
      "texts.zip.1         100%[===================>]  12.08M  14.9MB/s    in 0.8s    \n",
      "\n",
      "2016-09-18 17:12:56 (14.9 MB/s) - ‘texts.zip.1’ saved [12668137/12668137]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/texts.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  texts.zip\n",
      "  inflating: 10001.txt               \n",
      "  inflating: 10002.txt               \n",
      "  inflating: 10003.txt               \n",
      "  inflating: 10004.txt               \n",
      "  inflating: 10005.txt               \n",
      "  inflating: 10006.txt               \n",
      "  inflating: 10007.txt               \n",
      "  inflating: 10008.txt               \n",
      "  inflating: 10009.txt               \n",
      "  inflating: 10010.txt               \n",
      "  inflating: 10011.txt               \n",
      "  inflating: 10012.txt               \n",
      "  inflating: 10013.txt               \n",
      "  inflating: 10014.txt               \n",
      "  inflating: 10015.txt               \n",
      "  inflating: 10016.txt               \n",
      "  inflating: 10017.txt               \n",
      "  inflating: 10018.txt               \n",
      "  inflating: 10019.txt               \n",
      "  inflating: 10020.txt               \n",
      "  inflating: 10021.txt               \n",
      "  inflating: 10023.txt               \n",
      "  inflating: 10024.txt               \n",
      "  inflating: 10025.txt               \n",
      "  inflating: 10026.txt               \n",
      "  inflating: 10027.txt               \n",
      "  inflating: 10028.txt               \n",
      "  inflating: 10029.txt               \n",
      "  inflating: 10030.txt               \n",
      "  inflating: 10031.txt               \n",
      "  inflating: 10032.txt               \n",
      "  inflating: 10033.txt               \n",
      "  inflating: 10034.txt               \n",
      "  inflating: 10035.txt               \n",
      "  inflating: 10036.txt               \n",
      "  inflating: 10037.txt               \n",
      "  inflating: 10038.txt               \n",
      "  inflating: 10039.txt               \n",
      "  inflating: 10040.txt               \n",
      "  inflating: 10041.txt               \n",
      "  inflating: 10042.txt               \n",
      "  inflating: 10043.txt               \n",
      "  inflating: 10045.txt               \n",
      "  inflating: 10046.txt               \n",
      "  inflating: 10047.txt               \n",
      "  inflating: 10048.txt               \n",
      "  inflating: 10049.txt               \n",
      "  inflating: 10050.txt               \n",
      "  inflating: 10051.txt               \n",
      "  inflating: 10052.txt               \n",
      "  inflating: 10056.txt               \n",
      "  inflating: 10059.txt               \n",
      "  inflating: 10060.txt               \n",
      "  inflating: 10062.txt               \n",
      "  inflating: 12370.txt               \n",
      "  inflating: 12372.txt               \n",
      "  inflating: 12373.txt               \n",
      "  inflating: 12374.txt               \n",
      "  inflating: 12375.txt               \n",
      "  inflating: 12376.txt               \n",
      "  inflating: 12377.txt               \n",
      "  inflating: 12378.txt               \n",
      "  inflating: 12380.txt               \n",
      "  inflating: 12381.txt               \n",
      "  inflating: 12383.txt               \n",
      "  inflating: 12384.txt               \n",
      "  inflating: 12385.txt               \n",
      "  inflating: 12386.txt               \n",
      "  inflating: 1jcfs10.txt             \n",
      "  inflating: 2babb10.txt             \n",
      "  inflating: 3babb10.txt             \n",
      "  inflating: 50bab10.txt             \n",
      "  inflating: ajtl10.txt              \n",
      "  inflating: allyr10.txt             \n",
      "  inflating: alpsn10.txt             \n",
      "  inflating: balen10.txt             \n",
      "  inflating: baleng2.txt             \n",
      "  inflating: batlf10.txt             \n",
      "  inflating: bgopr10.txt             \n",
      "  inflating: brnte10.txt             \n",
      "  inflating: bstjg10.txt             \n",
      "  inflating: cambp10.txt             \n",
      "  inflating: canbe10.txt             \n",
      "  inflating: cantp10.txt             \n",
      "  inflating: cfrz10.txt              \n",
      "  inflating: crsnk10.txt             \n",
      "  inflating: esbio10.txt             \n",
      "  inflating: grybr10.txt             \n",
      "  inflating: mklmt10.txt             \n",
      "  inflating: morem10.txt             \n",
      "  inflating: mspcd10.txt             \n",
      "  inflating: penbr10.txt             \n",
      "  inflating: pgjr10.txt              \n",
      "  inflating: pntvw10.txt             \n",
      "  inflating: prcpg10.txt             \n",
      "  inflating: prhg10.txt              \n",
      "  inflating: prhsb10.txt             \n",
      "  inflating: rlsl110.txt             \n",
      "  inflating: rlsl210.txt             \n",
      "  inflating: rmlav10.txt             \n",
      "  inflating: sesli10.txt             \n",
      "  inflating: svyrd10.txt             \n",
      "  inflating: tecom10.txt             \n",
      "  inflating: utrkj10.txt             \n",
      "  inflating: vpasm10.txt             \n",
      "  inflating: wldsp10.txt             \n",
      "  inflating: wtrbs10.txt             \n",
      "  inflating: zncli10.txt             \n"
     ]
    }
   ],
   "source": [
    "!unzip texts.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use GNU parallel to count the 25 most common words across all the 109 texts in the zip file provided, with stop words removed. You may re-use your filters from Problem 3. Use the texts available at https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and- schedule/master/projects/project-01/texts.zip for this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!time ls texts/*.txt \\\n",
    "    | parallel --eta -j+0 \"grep -oE '\\w{{2,}}' {} | tr '[:upper:]' '[:lower:]' > totalwords.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!time sort totalwords.txt \\\n",
    "    | ./remove-stop-words.py\\\n",
    "    | ./split2.py\\\n",
    "    | ./lower.py\\\n",
    "    | sort\\\n",
    "    | uniq -c \\\n",
    "    | sort -rn \\\n",
    "    | head -25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
